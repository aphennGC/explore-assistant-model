{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aphennGC/explore-assistant-model/blob/main/2_Explore_Assistant_Demo_(Make_a_copy_first).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2vlowVCC4LH"
      },
      "source": [
        "# Explore Assistant\n",
        "This document provides instructions on how to install and customize the Explore Assistant demo. The demo is a web application that allows users to explore data in Looker by asking questions in natural language.\n",
        "\n",
        "DISCLAIMER : DO NOT INTENDED TO BE USED IN A PRODUCTION ENVIRONMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vqNHMAkkCbwa"
      },
      "outputs": [],
      "source": [
        "# @title Setup : Installing Required Librairies\n",
        "#!pip install looker_sdk\n",
        "!pip install google-cloud-aiplatform --upgrade --user\n",
        "!pip install pandas\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3eVa448EmSb"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1DpiR1VETP9"
      },
      "source": [
        "### Authenticating your notebook environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_kXw0EIDkd3"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-lVxwmtEywE"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2cmKCMhFh2c"
      },
      "source": [
        "Update Project and Region of your Vertex AI Project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVaXeHqHE3Zk"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "\n",
        "PROJECT_ID = \"project\"  # @param {type:\"string\"}\n",
        "LOCATION = \"region\" # @param {type:\"string\"}\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPe3ozloE9Er",
        "outputId": "70f9eedc-7771-40b9-bef9-911608f5254c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradio version: 4.12.0\n",
            "Vertex AI SDK version: 1.38.1\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import aiplatform\n",
        "import gradio as gr\n",
        "import urllib.parse\n",
        "import json\n",
        "\n",
        "# Print LangChain and Vertex AI versions\n",
        "print(f\"Gradio version: {gr.__version__}\")\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p57Ozc20HH3F"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AevRra6IHJWe"
      },
      "source": [
        "### Initiating Vertex AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyHoBkETHMNO"
      },
      "outputs": [],
      "source": [
        "# Definig parameters to be used.\n",
        "parameters = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 100,\n",
        "    \"top_p\": 0.8,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbqL9PfqIv9X"
      },
      "source": [
        "### Looker's Semantic Context and Examples\n",
        "Using the semantic layer as context for the LLM to extract the relevant field to build the query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Em7BbvhIWQ6"
      },
      "outputs": [],
      "source": [
        "# Default Base for Embedding the demo\n",
        "looker_base_url = \"https://ceworkshops.cloud.looker.com/embed/explore/thelookai/order_items?\"\n",
        "\n",
        "# Semantic Model Context : Result of the first Colab\n",
        "context = \"\"\"You\\'re a developer who would transalate questions to a structured URL query based on the following dicitonnary - choose only the fileds in the below description\n",
        "\n",
        "---- Past you Model Context Here\n",
        "---- Paste your Examples here\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3-l-ByzJVrA"
      },
      "source": [
        "### Gradio's Functions\n",
        "Function that would be used later by Gradio interface in order to render the results from Looker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KA8ZV1u_JhA-"
      },
      "outputs": [],
      "source": [
        "# Savings Logs to further train the model.\n",
        "def save_logs(input_text, output_text, filename):\n",
        "    formatted_input_text = json.dumps(input_text)[1:-1]\n",
        "    formatted_output_text = json.dumps(output_text)[1:-1]\n",
        "\n",
        "    with open(filename, 'a') as file:\n",
        "        line = f'{{\"input_text\": \"{formatted_input_text}\", \"output_text\": \"{formatted_output_text}\"}}\\n'\n",
        "        file.write(line)\n",
        "\n",
        "    return True\n",
        "\n",
        "# Define a function to process the search query and return results\n",
        "def search(query):\n",
        "    # Formatting prompt\n",
        "    llm = \"\"\"\n",
        "    input: {}\n",
        "    output: \"\"\".format(query)\n",
        "    # Building the prompt\n",
        "    predict = context + llm\n",
        "    # Retrieving Results from Model\n",
        "    response =  model.predict(predict,**parameters).text\n",
        "    response = response.strip()\n",
        "    # Saving Logs\n",
        "    if save_logs(query, response, \"logs.jsonl\"):\n",
        "            print(\"Logs Saved Correctly\")\n",
        "    # Percent Encoding\n",
        "    query_url = urllib.parse.quote(response, safe=':/?&=,[]{}')\n",
        "    # Building the Embedded URL\n",
        "    url = f\"{looker_base_url}{query_url}&toggle=dat,pik,vis&allow_login_screen=true\"\n",
        "    print(url)\n",
        "    return f'<iframe src=\"{url}\" style=\"width:100%; height:600px;\"></iframe>'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PgF09TVJx6q"
      },
      "source": [
        "## Running the demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA6JyurEJ60h"
      },
      "outputs": [],
      "source": [
        "# Create the Gradio app with custom layout\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    # Explore Assistant\n",
        "\n",
        "    \"\"\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=10) :\n",
        "            search_input = gr.Textbox(label=\"Type your question and press Enter\", lines=1, placeholder=\"Sales this week ?\")\n",
        "    with gr.Row():\n",
        "        search_results = gr.HTML()\n",
        "        search_input.submit(search, inputs=search_input, outputs=search_results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENVhL21XOX5v"
      },
      "source": [
        "## Showing Logs Saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DDmCQW4ObqA"
      },
      "outputs": [],
      "source": [
        "# Define the path to your logs.jsonl file\n",
        "jsonl_file_path = 'logs.jsonl'\n",
        "\n",
        "# Read the JSON Lines file and process each line\n",
        "with open(jsonl_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        # Load the line as a JSON object\n",
        "        json_data = json.loads(line)\n",
        "\n",
        "        # Extract the input and output strings\n",
        "        input_string = json_data.get('input_text', '')\n",
        "        output_string = json_data.get('output_text', '')\n",
        "\n",
        "        # Format and print the data\n",
        "        print(f'input: {input_string}')\n",
        "        print(f'output: {output_string}')\n",
        "        print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}